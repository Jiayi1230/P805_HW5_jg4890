---
title: "P8105_HW5_jg4890"
author: "Jiayi Ge"
date: "2024-11-01"
output: github_document
---
# Probelm 1
```{r}
check_birthday_share <- function(n) {
  birthdays <- sample(1:365, n, replace = TRUE)
  return(length(birthdays) != length(unique(birthdays)))
}

set.seed(123)
probabilities <- sapply(2:50, function(n) {
  results <- replicate(10000, check_birthday_share(n))
  mean(results)
})

library(ggplot2)
data <- data.frame(group_size = 2:50, probability = probabilities)
ggplot(data, aes(x = group_size, y = probability)) +
  geom_line() +
  geom_point() +
  labs(title = "Probability of at least two people sharing a birthday",
       x = "Group Size",
       y = "Probability")

```
As the group size increases, the probability of at least two people sharing a birthday rises rapidly. By a group size of around 50, the probability approaches nearly 100%. 


# Problem 2
```{r}
library(broom)
library(dplyr)

sim_power <- function(mu, n = 30, sigma = 5, alpha = 0.05) {
  sim_data <- tibble(
    x = rnorm(n, mean = mu, sd = sigma)
  )
  
  t_test_result <- t.test(sim_data$x, mu = 0)
  tidy_result <- broom::tidy(t_test_result)
  
  return(tibble(
    mu_hat = tidy_result$estimate,
    p_value = tidy_result$p.value
  ))
}
sim_results <- replicate(5000, sim_power(mu = 0, alpha = 0.05), simplify = FALSE) %>%
  bind_rows()

power <- mean(sim_results[["p_value"]] < 0.05)
power
```

```{r}
library(purrr)
mu_values <- 0:6
sim_results <- map_dfr(mu_values, function(mu) {
  replicate(5000, sim_power(mu = mu), simplify = FALSE) %>%
    bind_rows() %>%
    mutate(mu = mu)
})
power_results <- sim_results %>%
  group_by(mu) %>%
  summarize(power = mean(p_value < 0.05))

ggplot(power_results, aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(x = "True value of µ", y = "Power (proportion of null rejections)", 
       title = "Power of the test vs. Effect size (µ)")
```
The plot demonstrates a clear positive relationship between effect size (μ) and statistical power. As the true effect size increases, the probability of correctly rejecting a false null hypothesis also increases. This indicates that larger deviations from the null hypothesis are more likely to be detected.

However, it's important to note that the relationship between effect size and power is not strictly linear. As the effect size becomes very large, the power plateaus. This suggests that beyond a certain point, further increases in effect size may not substantially increase the probability of detecting a true effect.

```{r}
avg_mu_hat <- sim_results %>%
  group_by(mu) %>%
  summarize(
    avg_mu_hat_all = mean(mu_hat),
    avg_mu_hat_reject = mean(mu_hat[p_value < 0.05])
  )

ggplot(avg_mu_hat, aes(x = mu)) +
  geom_line(aes(y = avg_mu_hat_all, color = "All Samples")) +
  geom_line(aes(y = avg_mu_hat_reject, color = "Rejected Samples")) +
  geom_point(aes(y = avg_mu_hat_all, color = "All Samples")) +
  geom_point(aes(y = avg_mu_hat_reject, color = "Rejected Samples")) +
  labs(x = "True value of µ", y = "Average estimate of µ̂", 
       title = "Average estimate of µ̂ vs. True µ",
       color = "Sample Type")

```

The red line for "All Samples" closely follows the true μ, reflecting unbiased estimation across all simulations. In contrast, the blue line for "Rejected Samples" (samples where the null hypothesis was rejected with p-value<0.05) generally lies above the red line, especially for lower values of $\hat{u}$. This occurs because the reject samples focuses on the average estimated μ only for those simulations where the null hypothesis was rejected causing a slight overestimation of μ due to potential selection bias (when only considering samples where the null was rejected, there is a tendency to include cases with higher estimates of μ). While there is still a positive association between the true and estimated values, the relationship becomes more pronounced as the true effect size (μ) increases. As the effect size increases, the power of the test improves, making the estimated values more accurate for both lines.  Consequently, the sample average of $\hat{u}$ for tests that reject the null hypothesis does not accurately equal the true μ.

# Problem 3
```{r}
library(tidyverse)

homicides <- read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

homicides_summary <- homicides %>%
  mutate(city_state = paste(city, state, sep = ", ")) %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )

baltimore_data <- homicides_summary %>% filter(city_state == "Baltimore, MD")
baltimore_prop_test <- prop.test(
  baltimore_data$unsolved_homicides,
  baltimore_data$total_homicides
)
baltimore_summary <- tidy(baltimore_prop_test)

baltimore_estimate <- baltimore_summary %>%
  select(estimate, conf.low, conf.high)

city_proportions <- homicides_summary %>%
  mutate(
    prop_test = map2(unsolved_homicides, total_homicides, ~ prop.test(.x, .y)),
    prop_summary = map(prop_test, tidy)
  ) %>%
  unnest(prop_summary) %>%
  select(city_state, estimate, conf.low, conf.high)

city_proportions %>%
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Proportion of Unsolved Homicides"
  )
```
There are `r nrow(homicides)` rows and `r ncol(homicides)` in the raw data. Some variables include `uid`,`victim_last`, `victim_first`, `victim_race`, `victim_age`, `victim_sex`, `city`, `state`, `lat`, and `lon`.
